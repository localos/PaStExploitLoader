#!/usr/bin/env perl -w

#####################################################
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
#####################################################


#####################################################
#
# Simple script for downloading exploits 
# from packetstorm.com
#
# Author: solacol
# Version: 0.1a_dev
#
#####################################################
#
#
# TODO:
#	- Implement needed stuff ^^
#	- Check for wget
#	- Check perl modules
#	- Check if path/dir exists
#	- Store years and months in array or use some posix shit
#	- Check md5
#	- Check if file already exists (use checksum to compare)
#	- Use reasonable name for file storage
#
# CHANGELOG:
#	- Very basic skeleton
#
###


use strict;
use warnings;
use POSIX qw{ strftime };
use LWP::UserAgent;
use HTML::TokeParser::Simple;


# Url, dir, file related stuff 
my $baseUrl = 'https://packetstormsecurity.com';
my $searchUrl = $baseUrl.'/search/?q=Packet+Storm+New+Exploits+For';
my $storDir = '/tmp';

# Some additional config stuff
my $startYear = '2000';
my $startMonth = 'June';
my $skipYearly = 'yes';
my $pageCount = 0;

# Preparing for ssl
my $usag = LWP::UserAgent->new(ssl_opts => {verify_hostname => 0});

# Get website
my @a_website = fct_getFileContentOnly($searchUrl,$usag);

# Check for "errors" and get page count
if(scalar(@a_website) > 1 && ( ($pageCount) = grep(/\<strong\>Page [0-9]{1,} of [0-9]{1,}\<\/strong\>/, @a_website) ) ){ # TODO test last condition
    # Construtor
    my $parser = HTML::TokeParser::Simple->new(url => "$baseUrl");

    # TODO error handling
    
    # Loop through html and extract hrefs
    while(my $tag = $parser->get_tag('a')){
	    my $href = $tag->get_attr('href');

        # Check for needed href
        next unless(defined($href) && $href =~ m/\/[0-9]{4,4}\-exploits\.tgz$/);

        my $getUrl = $baseUrl.$href;

        print("$getUrl\n");









    }
}
else{
    die("FAILURE: Website seems to be malformed?! ".__FILE__.':'.__LINE__." $!\n");
}




### Function for downloading a file
sub fct_preChecks{

# LWP::Protocol::https;
# Net::SSLeay
# IO::Socket::SSL

    # TODO check perl modules and needed software

}

### Function for downloading a file
sub fct_getFileOnline{
    my $url = $_[0];
    my $file = $_[1];

    print("Download file $url ...\n");

    # Simple fallback to wget if getstore fails
    unless(getstore($url, $file) == 200){
        # Fallback if getstore() fails
        warn("WARNING: Problems!? Trying wget ...".__FILE__.':'.__LINE__." \n");
        return(1), warn("FAILURE: Could not get file $file! ".__FILE__.':'.__LINE__." $!\n") if(system("wget\ \-q\ $url\ \-O\ $file"));
    }

    return(0);
}

### Function to get online content without saving the file
sub fct_getFileContentOnly{
    my $url = $_[0];
    my $obj = $_[1];
    my $content = '';
    my @a_content = ();
    my @a_rray = ();
    
    # Get content of url and save it to var
    unless(defined($content = $obj->get($url))){
        # Fallback if get() fails
        warn("WARNING: Problems!? Trying wget ...".__FILE__.':'.__LINE__." \n");
        @a_content = `wget\ \-q\ \-O\ \-\ $url`;

        if(scalar(@a_content) > 1){
            return(\@a_content);
        }
        else{
            warn("FAILURE: Could not get content of $url! $content->status_line ".__FILE__.':'.__LINE__." $!\n");
            return(1);
        }
    }
# TODO clean up, but currently nedd this for testing
print ($content->decoded_content."\n");
    # Split downloaded content on newlines to array
    #@a_content = split("\n",$content);
    #return(\@a_content);
    return($content->decoded_content);
}

### Function to check if a directory is existent
sub fct_checkDir{
    my $dir = $_[0];

    # Check if directory is given
    return(1), warn("FAILURE: No directory given! ".__FILE__.':'.__LINE__." \n")  unless(defined($dir));

    # Check if directory exists
    if(-d "$dir" ){
        return(0); # found, existent
    }
    elsif(! -d "$dir"){
        return(2); # not found, not existent
    }
    else{
        warn("FAILURE: ".__FILE__.':'.__LINE__." $!\n");
        return(1);
    }
}

### Function to check if a file is existent
sub fct_checkFile{
    my $file = $_[0];

    # Check if file is given
    return(1), warn("FAILURE: No file given! ".__FILE__.':'.__LINE__." \n")  unless(defined($file));

    # Check if file exists
    if(-f "$file" ){
        return(0); # found, existent
    }
    elsif(! -f "$file"){
        return(2); # not found, not existent
    }
    else{
        warn("FAILURE: ".__FILE__.':'.__LINE__." $!\n");
        return(1);
    }
}
